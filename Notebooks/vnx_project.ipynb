{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern matching kernel\n",
    "\n",
    "This notebook shows you how to use the *pattern matching kernel*.\n",
    "The design provides network connectivity using User Datagram Protocol (UDP) as the transport protocol.\n",
    "\n",
    "Let's have a look at the *project* design.\n",
    "\n",
    "There are 4 Kernels:\n",
    "* CMAC: provides the translation between physical signals to AXI4-Stream interface\n",
    "* Network layer: provides a bridge between raw Ethernet packets and the application using UDP as transport layer\n",
    "    * ARP provides translation between MAC and IP addresses\n",
    "    * ICMP provides ping capabilities\n",
    "    * The UDP module has a 16-entry table with socket information that needs to be filled in before running\n",
    "* krnl_proj: free running kernel matching the input stream to possible patterns\n",
    "* krnl_s2mm: read data from the stream and copy it to memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPGA Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 'HOT Reset' on '0000:02:00.1'\n",
      "Are you sure you wish to proceed? [Y/n]: Y (Force override)\n",
      "Successfully reset Device[0000:02:00.1]\n"
     ]
    }
   ],
   "source": [
    "#Uncomment the next line and run to reset the FPGA if it is not taking programming or otherwise misbehaving\n",
    "!xbutil reset --device 0000:02:00.1 --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and program FPGA\n",
    "In this section we need to import the `pynq` and python packages that will be used in the rest of this notebook. We also import the `vnx_utils.py` file with helper functions to set up the vnx examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynq\n",
    "import numpy as np\n",
    "import vnx_utils\n",
    "import socket\n",
    "import time\n",
    "import threading\n",
    "import struct\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to define the current device, only if there is more than one Alveo card on the host. First let's check how many devices are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) xilinx_u55c_gen3x16_xdma_base_3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pynq.Device.devices)):\n",
    "    print(\"{}) {}\".format(i, pynq.Device.devices[i].name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "currentDevice = pynq.Device.devices[0]\n",
    "xclbin = \"../project.intf0.xilinx_u55c_gen3x16_xdma_3_202210_1/vnx_project_if0.xclbin\"\n",
    "ol = pynq.Overlay(xclbin,device=currentDevice)\n",
    "network_layer = ol.networklayer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Alveo IP: 192.168.100.2\n",
      "{'HWaddr': '00:0a:35:02:9d:02', 'inet addr': '192.168.100.2', 'gateway addr': '192.168.100.1', 'Mask': '255.255.255.0'}\n",
      "Configuring Sockets...\n",
      "Sending warm-up bursts to lock ARP... Done.\n",
      "Network Configured.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define IPs\n",
    "alveo_ipaddr = '192.168.100.2'\n",
    "sw_ip = '192.168.100.1'\n",
    "\n",
    "print(f\"Configuring Alveo IP: {alveo_ipaddr}\")\n",
    "\n",
    "# 1. Set Alveo IP Address\n",
    "print(network_layer.set_ip_address(alveo_ipaddr, debug=True))\n",
    "\n",
    "# 2. Configure Sockets\n",
    "print(\"Configuring Sockets...\")\n",
    "network_layer.sockets[0] = (sw_ip, 50446, 60133, True)\n",
    "network_layer.sockets[1] = (sw_ip, 38746, 62781, True)\n",
    "\n",
    "network_layer.populate_socket_table(debug=True)\n",
    "\n",
    "# 4. ARP Discovery (Broadcast to ensure the Host sees us)\n",
    "network_layer.arp_discovery()\n",
    "\n",
    "SW_PORT = ol.networklayer_0.sockets[1]['theirPort']\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) # UDP\n",
    "sock.bind(('', SW_PORT))\n",
    "alveo_port = ol.networklayer_0.sockets[1]['myPort']\n",
    "\n",
    "# --- WARM-UP ---\n",
    "print(\"Sending warm-up bursts to lock ARP...\", end=\"\")\n",
    "sock.sendto(b'\\x00' * 64, (alveo_ipaddr, alveo_port))\n",
    "time.sleep(0.1)\n",
    "print(\" Done.\")\n",
    "time.sleep(1.0) # Give the network a second to settle\n",
    "# -------------------------------\n",
    "\n",
    "print(f\"Network Configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patteerns Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2662 patterns.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_patterns_header(file_path):\n",
    "    patterns_db = {}\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Error: patterns.h not found.\")\n",
    "        return {}\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    re_data = re.search(r'const unsigned char PATTERN_DATA\\[\\d+\\]\\[\\d+\\]\\s*=\\s*\\{(.*?)\\};', content, re.DOTALL)\n",
    "    re_len = re.search(r'const int PATTERN_LENGTHS\\[\\d+\\]\\[\\d+\\]\\s*=\\s*\\{(.*?)\\};', content, re.DOTALL)\n",
    "    re_counts = re.search(r'const int NUM_PATTERNS_MATRIX\\[\\d+\\]\\s*=\\s*\\{([^}]+)\\};', content)\n",
    "    re_offsets = re.search(r'const int PATTERN_OFFSETS\\[\\d+\\]\\[\\d+\\]\\s*=\\s*\\{(.*?)\\};', content, re.DOTALL)\n",
    "\n",
    "    if not (re_data and re_len and re_counts and re_offsets):\n",
    "        return {}\n",
    "\n",
    "    def parse_c_array(raw_str):\n",
    "        rows = raw_str.split('},')\n",
    "        matrix = []\n",
    "        for row in rows:\n",
    "            clean_row = row.replace('{', '').replace('}', '').strip()\n",
    "            if clean_row:\n",
    "                items = []\n",
    "                for x in clean_row.split(','):\n",
    "                    x = x.strip()\n",
    "                    if not x: continue\n",
    "                    try:\n",
    "                        val = int(x, 16) if x.startswith('0x') else int(x)\n",
    "                        items.append(val)\n",
    "                    except ValueError: continue\n",
    "                matrix.append(items)\n",
    "        return matrix\n",
    "\n",
    "    data_matrix = parse_c_array(re_data.group(1))\n",
    "    len_matrix = parse_c_array(re_len.group(1))\n",
    "    offset_matrix = parse_c_array(re_offsets.group(1))\n",
    "    counts = [int(x.strip()) for x in re_counts.group(1).split(',')]\n",
    "\n",
    "    global_id_offsets = [0] * len(counts)\n",
    "    for i in range(1, len(counts)):\n",
    "        global_id_offsets[i] = global_id_offsets[i-1] + counts[i-1]\n",
    "\n",
    "    for n in range(min(len(counts), len(data_matrix))):\n",
    "        for p in range(counts[n]):\n",
    "            if n >= len(len_matrix) or p >= len(len_matrix[n]): continue\n",
    "            p_len = len_matrix[n][p]\n",
    "            p_start = offset_matrix[n][p]\n",
    "            if p_len > 0 and (p_start + p_len) <= len(data_matrix[n]):\n",
    "                pat_bytes = data_matrix[n][p_start : p_start + p_len]\n",
    "                patterns_db[p + global_id_offsets[n]] = pat_bytes\n",
    "\n",
    "    return patterns_db\n",
    "\n",
    "# Load patterns\n",
    "patterns_map = parse_patterns_header(\"../Project_kernels_HLS/src/patterns.h\") \n",
    "print(f\"Loaded {len(patterns_map)} patterns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Payload Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametric Config: DWIDTH=32 (4 Bytes/Beat)\n",
      "Verification Type: <class 'numpy.uint32'>\n",
      "Generated 100 packets.\n",
      "Total Expected Beats: 25600\n"
     ]
    }
   ],
   "source": [
    "KERNEL_DWIDTH_BITS = 32  \n",
    "\n",
    "# Derived Constants\n",
    "BYTES_PER_BEAT = KERNEL_DWIDTH_BITS // 8\n",
    "\n",
    "# Mapping bit width to numpy types for verification\n",
    "DTYPE_MAP = {\n",
    "    8:  np.uint8,\n",
    "    16: np.uint16,\n",
    "    32: np.uint32,\n",
    "    64: np.uint64\n",
    "}\n",
    "KERNEL_DTYPE = DTYPE_MAP[KERNEL_DWIDTH_BITS]\n",
    "\n",
    "print(f\"Parametric Config: DWIDTH={KERNEL_DWIDTH_BITS} ({BYTES_PER_BEAT} Bytes/Beat)\")\n",
    "print(f\"Verification Type: {KERNEL_DTYPE}\")\n",
    "\n",
    "def generate_host_payloads(patterns, num_packets=100, payload_size=1024):\n",
    "    packets = []\n",
    "    expected_map = {}\n",
    "    keys = list(patterns.keys())\n",
    "    \n",
    "    # We track the global byte count because S2MM writes a continuous stream\n",
    "    # derived from the incoming packets.\n",
    "    global_byte_counter = 0\n",
    "    \n",
    "    for i in range(num_packets):\n",
    "        data = bytearray(payload_size)\n",
    "        \n",
    "        if keys:\n",
    "            pid = np.random.choice(keys)\n",
    "            pat = patterns[pid]\n",
    "            # Padding check\n",
    "            if len(pat) < (payload_size - 64):\n",
    "                offset = 64\n",
    "                data[offset : offset+len(pat)] = pat\n",
    "\n",
    "                match_byte_local = offset + len(pat) - 1\n",
    "                \n",
    "                # 2. Global Byte index in the entire stream\n",
    "                match_byte_global = global_byte_counter + match_byte_local\n",
    "                \n",
    "                beat = match_byte_global // BYTES_PER_BEAT\n",
    "                \n",
    "                expected_map[beat] = pid\n",
    "        \n",
    "        packets.append(data)\n",
    "        global_byte_counter += payload_size\n",
    "        \n",
    "    # Calculate total beats for buffer allocation\n",
    "    # (Total Bytes / Bytes_Per_Beat)\n",
    "    total_beats = global_byte_counter // BYTES_PER_BEAT\n",
    "        \n",
    "    return packets, expected_map, total_beats\n",
    "\n",
    "# Generate\n",
    "PAYLOAD_SIZE = 1024\n",
    "NUM_PACKETS = 100\n",
    "packet_list, expected_map, total_beats = generate_host_payloads(patterns_map, NUM_PACKETS, PAYLOAD_SIZE)\n",
    "\n",
    "print(f\"Generated {len(packet_list)} packets.\")\n",
    "print(f\"Total Expected Beats: {total_beats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loopback configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiver Thread Defined.\n"
     ]
    }
   ],
   "source": [
    "print_lock = threading.Lock()\n",
    "done = threading.Event()\n",
    "\n",
    "# Global variable to store what the thread captures\n",
    "captured_results = None\n",
    "\n",
    "def socket_receive_threaded(sock, size): \n",
    "    global captured_results\n",
    "    \n",
    "    BYTES_PER_PACKET = 1024 \n",
    "    \n",
    "    shape_global = (size,)\n",
    "    shape_local = (BYTES_PER_PACKET,)\n",
    "    \n",
    "    recv_data_global = np.empty(shape_global, dtype = np.uint8)\n",
    "    data_partial = np.empty(shape_local, dtype = np.uint8)\n",
    "    \n",
    "    num_it = (size // BYTES_PER_PACKET)\n",
    "    \n",
    "    sum_bytes = 0\n",
    "    connection = 'None'\n",
    "    \n",
    "    # Set timeout so we don't hang forever if packets are lost\n",
    "    sock.settimeout(5.0)\n",
    "    \n",
    "    try:\n",
    "        for m in range(num_it):\n",
    "            # recvfrom_into writes directly into data_partial\n",
    "            res = sock.recvfrom_into(data_partial) \n",
    "            \n",
    "            # Copy partial buffer to global buffer\n",
    "            start_idx = m * BYTES_PER_PACKET\n",
    "            end_idx = start_idx + BYTES_PER_PACKET\n",
    "            \n",
    "            # Safety check for last packet\n",
    "            if end_idx > size: end_idx = size\n",
    "                \n",
    "            recv_data_global[start_idx : end_idx] = data_partial[:(end_idx-start_idx)]\n",
    "            \n",
    "            sum_bytes = sum_bytes + int(res[0])\n",
    "            connection = res[1]\n",
    "            \n",
    "        msg = \"SUCCESS\" \n",
    "    except socket.timeout:\n",
    "        msg = \"TIMEOUT\"\n",
    "    except Exception as e:\n",
    "        msg = f\"ERROR: {e}\"\n",
    "\n",
    "    # Export data for the verification cell\n",
    "    captured_results = recv_data_global\n",
    "\n",
    "    print_lock.acquire()\n",
    "    print (\"\\n[Thread] Reception finished. Status: {}. Total received {:,} bytes from {}\".format(msg, sum_bytes, connection))\n",
    "    print_lock.release()\n",
    "    \n",
    "    done.set()\n",
    "\n",
    "print(\"Receiver Thread Defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending 100 packets to 192.168.100.2:62781...\n",
      "\n",
      "[Thread] Reception finished. Status: SUCCESS. Total received 102,400 bytes from ('192.168.100.2', 62781)\n",
      "Sent 102400 bytes. Waiting for return traffic...\n",
      "Main: Thread signaled completion.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Setup Sockets\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "sock.bind(('', SW_PORT)) # Bind to Host Port\n",
    "sock.settimeout(5.0)\n",
    "\n",
    "# 2. Reset Threading\n",
    "print_lock = threading.Lock()\n",
    "done = threading.Event()\n",
    "captured_results = None \n",
    "done.clear()\n",
    "\n",
    "# 3. Start Receiver Thread\n",
    "expected_rx_bytes = total_beats * (KERNEL_DWIDTH_BITS // 8)\n",
    "t = threading.Thread(target=socket_receive_threaded, args=(sock, expected_rx_bytes))\n",
    "t.start()\n",
    "\n",
    "\n",
    "# 4. Start Main Transmission\n",
    "print(f\"Sending {len(packet_list)} packets to {alveo_ipaddr}:{alveo_port}...\")\n",
    "sent_bytes = 0\n",
    "\n",
    "for pkt in packet_list:\n",
    "    sock.sendto(pkt, (alveo_ipaddr, alveo_port))\n",
    "    sent_bytes += len(pkt)\n",
    "    time.sleep(0.0005) # Flow control\n",
    "\n",
    "print(f\"Sent {sent_bytes} bytes. Waiting for return traffic...\")\n",
    "\n",
    "# 5. Wait for Completion\n",
    "is_done = done.wait(timeout=10)\n",
    "\n",
    "if is_done:\n",
    "    print(\"Main: Thread signaled completion.\")\n",
    "else:\n",
    "    print(\"Main: Timed out (Likely packet loss).\")\n",
    "\n",
    "# Cleanup\n",
    "sock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronizing stream...\n",
      "Stream Locked! Global Shift: 0 beats.\n",
      "\n",
      "Verifying 100 Patterns with shift 0...\n",
      "\n",
      "Matches: 100, Misses: 0\n",
      "TEST PASSED!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if captured_results is None or len(captured_results) == 0:\n",
    "    print(\"ERROR: No data captured.\")\n",
    "else:\n",
    "    # 1. View Data\n",
    "    output_beats = captured_results.view(KERNEL_DTYPE)\n",
    "    \n",
    "    # 2. Find Stream Alignment (Global Shift)\n",
    "    # We check the first 5 expected patterns to see if they appear shifted\n",
    "    # by multiples of packet size (256 beats for DWIDTH=32)\n",
    "    packet_size_beats = 1024 // (KERNEL_DWIDTH_BITS // 8) # 256 for DWIDTH=32\n",
    "    \n",
    "    global_shift = 0\n",
    "    detected = False\n",
    "    \n",
    "    print(\"Synchronizing stream...\")\n",
    "    \n",
    "    # Sort map to find the first few expected beats\n",
    "    sorted_map = sorted(expected_map.items())\n",
    "    first_beat, first_id = sorted_map[0]\n",
    "    \n",
    "    # Search for the first pattern in a wide range\n",
    "    search_window = packet_size_beats * 5 # Look within +/- 5 packets\n",
    "    \n",
    "    for offset in range(-search_window, search_window):\n",
    "        check_idx = first_beat + offset\n",
    "        if 0 <= check_idx < len(output_beats):\n",
    "            if output_beats[check_idx] == first_id:\n",
    "                global_shift = offset\n",
    "                detected = True\n",
    "                break\n",
    "    \n",
    "    if detected:\n",
    "        print(f\"Stream Locked! Global Shift: {global_shift} beats.\")\n",
    "        if abs(global_shift) == packet_size_beats:\n",
    "            print(f\" -> DIAGNOSIS: Exactly 1 packet ({global_shift} beats) was lost/shifted.\")\n",
    "    else:\n",
    "        print(\"WARNING: Could not synchronize stream. Verification will likely fail.\")\n",
    "\n",
    "    # 3. Verify with Shift Applied\n",
    "    matches = 0\n",
    "    misses = 0\n",
    "    \n",
    "    print(f\"\\nVerifying {len(expected_map)} Patterns with shift {global_shift}...\")\n",
    "\n",
    "    for beat, exp_id in sorted_map:\n",
    "        \n",
    "        # Apply the detected global shift to our expectation\n",
    "        aligned_beat = beat + global_shift\n",
    "        \n",
    "        found = False\n",
    "        # Small window for local jitter\n",
    "        local_window = 10 \n",
    "        \n",
    "        for w in range(-local_window, local_window):\n",
    "            idx = aligned_beat + w\n",
    "            if 0 <= idx < len(output_beats):\n",
    "                if output_beats[idx] == exp_id:\n",
    "                    found = True\n",
    "                    break\n",
    "                    \n",
    "        if found:\n",
    "            matches += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "            if misses <= 5:\n",
    "                val = output_beats[aligned_beat] if 0 <= aligned_beat < len(output_beats) else -1\n",
    "                print(f\"Missed {exp_id} at Expected Beat {beat} (Aligned {aligned_beat}). Found: {val}\")\n",
    "\n",
    "    print(f\"\\nMatches: {matches}, Misses: {misses}\")\n",
    "    \n",
    "    if matches > 0 and misses == 0:\n",
    "        print(\"TEST PASSED!\")\n",
    "    elif matches > 0:\n",
    "        print(\"TEST PASSED with Packet Loss (Partial Data).\")\n",
    "    else:\n",
    "        print(\"TEST FAILED.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating debug report: debug_results.txt ...\n",
      "Report saved. Open 'debug_results.txt' to analyze.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_debug_report(filename, expected_map, output_buffer):\n",
    "    print(f\"Generating debug report: {filename} ...\")\n",
    "    \n",
    "    \n",
    "    # CRITICAL FIX: View as uint16 because DWIDTH=16\n",
    "    # This prevents the \"big number\" packing issue\n",
    "    output_data = captured_results.view(KERNEL_DTYPE)\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        # --- SECTION 1: EXPECTED VS ACTUAL ---\n",
    "        f.write(\"=======================================================\\n\")\n",
    "        f.write(\"SECTION 1: VERIFICATION (Expected vs Actual)\\n\")\n",
    "        f.write(\"=======================================================\\n\")\n",
    "        f.write(f\"{'BEAT':<12} | {'EXPECTED ID':<12} | {'ACTUAL ID':<12} | {'STATUS'}\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        \n",
    "        matches = 0\n",
    "        misses = 0\n",
    "        \n",
    "        # Sort by beat to keep it chronological\n",
    "        for beat, exp_id in sorted(expected_map.items()):\n",
    "            # Safety check for bounds\n",
    "            if beat < len(output_data):\n",
    "                act_id = output_data[beat]\n",
    "            else:\n",
    "                act_id = -1 # Out of bounds\n",
    "            \n",
    "            # Check for exact match\n",
    "            status = \"MATCH\" if act_id == exp_id else \"MISS\"\n",
    "            \n",
    "            # Check for near-miss (shifted by +/- 4 beats)\n",
    "            if status == \"MISS\":\n",
    "                for offset in range(-4, 5):\n",
    "                    check_idx = beat + offset\n",
    "                    if 0 <= check_idx < len(output_data):\n",
    "                        if output_data[check_idx] == exp_id:\n",
    "                            status = f\"SHIFTED ({offset:+d})\"\n",
    "                            break\n",
    "            \n",
    "            if status == \"MATCH\": \n",
    "                matches += 1\n",
    "            else: \n",
    "                misses += 1\n",
    "                \n",
    "            f.write(f\"{beat:<12} | {exp_id:<12} | {act_id:<12} | {status}\\n\")\n",
    "            \n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        f.write(f\"SUMMARY: Matches: {matches}, Misses: {misses}, Total: {len(expected_map)}\\n\\n\\n\")\n",
    "\n",
    "        # --- SECTION 2: RAW HARDWARE DETECTIONS ---\n",
    "        f.write(\"=======================================================\\n\")\n",
    "        f.write(\"SECTION 2: ALL HARDWARE DETECTIONS (Non-zero outputs)\\n\")\n",
    "        f.write(\"=======================================================\\n\")\n",
    "        f.write(f\"{'BEAT':<12} | {'DETECTED ID'}\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        \n",
    "        # Scan entire buffer for any non-zero value\n",
    "        hw_detections = np.nonzero(output_data)[0]\n",
    "        \n",
    "        if len(hw_detections) == 0:\n",
    "            f.write(\"No patterns detected (Output is all zeros).\\n\")\n",
    "        else:\n",
    "            for beat in hw_detections:\n",
    "                val = output_data[beat]\n",
    "                f.write(f\"{beat:<12} | {val}\\n\")\n",
    "                \n",
    "    print(f\"Report saved. Open '{filename}' to analyze.\")\n",
    "\n",
    "# Run the export (using the correct buffer variable 'output_buffer')\n",
    "save_debug_report(\"debug_results.txt\", expected_map, output_beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
